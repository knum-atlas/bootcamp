---
title: "Bootcamp 2023 - klasyfikacja"
author: "KNUM ATLAS"
format: 
  html:
    warning: false
    message: false
    self-contained: true
    self-contained-math: true
    toc: true
    toc-title: Spis treści
---

```{r}
library(tidymodels)
library(tidyverse)

data("spam7", package = "DAAG")
df <- data.frame(spam7)
```

# Spam E-mail Data

## Opis

Dane składają się z 4601 wiadomości e-mail, z których 1813 zostało zidentyfikowanych jako spam. Jest to podzbiór pełnego zbioru danych, zawierający tylko sześć z 57 zmiennych objaśniających znajdujących się pełnym zbiorze danych.

<https://rdrr.io/cran/DAAG/man/spam7.html>

```{r}
head(df)
```

Kolumny w naszym zadaniu:

-   crl.tot - całkowita długość nieprzerwanych sekwencji wielkich liter

-   dollar - wystąpienia znaku `$` jako procent wszystkich znaków

-   bang - wystąpienia znaku `!` jako procent wszystkich znaków

-   money - wystąpienia słowa `money` jako procent wszystkich słów

-   n000 - wystąpienia ciągu `000` jako procent wszystkich słów

-   make - wystąpienia słowa `make` jako procent wszystkich słów

-   yesno - zmienna wynika określająca czy dana wiadomość była spamem

```{r}
str(df)
```

```{r}
summary(df,digits = 1)
```

## Czyszczenie zbioru danych

Zmiana kolumny `yesno` w zmienną binarną, czyli tak aby zamiast `y` i `n` przyjomwała wartości `1` i `0` (dla wygody zmieniliśmy również nazwę na `spam`)

```{r}
colnames(df)[colnames(df) == 'yesno'] <- 'spam' #zmiana nazwy zmiennej
df$spam <- ifelse(df$spam == 'y', 1, 0) #zmiana wartośc w kolumnie na 1 i 0
```

```{r}
head(df)
```

```{r}
summary(df,digits = 1)
```

Bardzo wygodną (i dobrze wyglądającą) metodą do podsumowań tabelarycznych jest funkcja `stargazer` z pakietu o tej samej nazwie.

```{r}
library(stargazer)
stargazer(df, type = "text") #można korzystać też z innych formatów np. latex
```

Następnie możemy sprawdzić za pomocą macierzy korelacji jak mocno zmienne są ze sobą skorelowane

```{r}
library(rstatix)
corr <- cor_mat(df) #wyliczamy macierz korelacji
corr

corr_pval <- cor_pmat(df) #obliczamy istotność korelacji
corr_pval
```

```{r}
library(ggcorrplot)
ggcorrplot(corr, p.mat=corr_pval, lab=T) #rysujemy wykres
```

Istotną kwestią jest sprawdzenie czy mamy do czynienia z zadaniem niezbalanoswanym, możemy to sprawdzić za pomocą zliczenia obserwacji (i metod graficznych)

Zamieniamy też zmienną wynikową na faktor żeby było łatwiej na niej dalej działać

```{r}
df$spam <- as_factor(df$spam)
```

```{r}
plyr::count(df, 'spam') #funkcja z biblioteki plyr to zliczenia obserwacji
```

Wykres możemy narysować korzystając z pakietu `ggplot2`

```{r}
ggplot(df,aes(x = spam)) +
  geom_bar(fill="blue")+
  xlab("spam")
```

Wykresy `ramka-wąsy` (*ang. `boxplot`*)

Możemy sprawdzić rozkład wartości poszczególnych zmiennych

```{r}
library(ggpubr)
ggboxplot(df, y = "money")
ggboxplot(df, y = c("money", "dollar"), combine = T) #połączenie dwóch wykresów
ggboxplot(df, x = "spam", y="money") #rozkład zmiennej w podziale na spam
```

## Klasyfikacja

Zadanie to będzie wykonane w filozofii `tidymodels` (co możecie potraktować jako wstęp do pracy z tym pakietem)

### Podział zbioru

Po tym jak już przyjżeliśmy się naszym danym możemy przejść do procesu modelowania. Pierwszym etapem jest zawsze podział zbioru na uczący i testowy

```{r}
split <- initial_split(df,0.85, seed = 47) #funkcja tworząca podział
df_test <- testing(split) #tworznie zbioru testowego
df_train <- training(split) #tworzenie zbioru treningowego
```

```{r}
nrow(df_test)
nrow(df_train)
```

### Zdefiniowanie modeli

Następnie możemy zdefiniować modele które będziemy potem chcieli wykorzystać.

Model definiujemy za pomocą odpowaidającej mu funkcji podając:

-   Rodzaj zadania - klasyfikacja lub regresja

-   Silnik modelu

-   Hiperparametry - jeżeli chcemy dostrajać model lub ustawić jakieś konkretne (można zostawić puste)

```{r}
#Model drzewa decyzyjnego
tree_mod <- decision_tree(mode = "classification",
                          engine = "rpart")

#Model drzewa z ustawionymi hiperparametrami
tree_mod2 <- decision_tree(mode = "classification",
                          engine = "rpart",
                          min_n = 20,
                          tree_depth = 7)

#Model regresji logistycznej
logreg_mod <- logistic_reg(mode = "classification",
                           engine = "glm")
```

### Tworzenie przepływu pracy

Można to porównać do tworzenia 'pojemnika' w którym będziemy trzymali nasz model i dodwali mu niezbędne rzeczy oraz prowadzili na nim wszystkie dalsze operacje np. uczenie.

```{r}
tree_wf <- workflow() %>% #tworzymy przepływ pracy
  add_model(tree_mod) %>% #dodajemy do niego model
  add_formula(spam~.) #dodajemy formułe
```

Dzięki `workflow` możemy w bardzo prosty sposób dodawać też preprocessing danych za pomocą 'przepisów'.
Przykładowo regresja logistyczna wymaga normalizacji predyktorów

```{r}
reg_rec <- recipe(spam~., data = df_train) %>% #definiujemy przepis podając formułę i zbiór danych
  step_normalize() #dodajemy krok normalizujący dane
```

```{r}
reg_wf <- workflow() %>% 
  add_model(logreg_mod) %>% #dodajemy model
  add_recipe(reg_rec) #dodajemy wcześniej przygotowany przepis

#nie musimy dodwać formuły ponieważ podana została w przepisie
```

### Uczenie modelu

Przekazujemy przepływ pracy do funkcji `fit`

```{r}
tree_wf_fit <- tree_wf %>% 
  fit(data = df_train)

reg_wf_fit <- reg_wf %>% 
  fit(data = df_train)
```

```{r}
tree_wf_fit
reg_wf_fit
```

### Predykcja i testowanie

```{r}
tree_pred <- predict(tree_wf_fit,df_test) #ramka danych z predykcją
head(tree_pred)

reg_pred <- predict(reg_wf_fit,df_test) #ramka danych z predykcją
head(reg_pred)
```

Łączymy predykcje modelu i wartość rzeczywistą ze zbioru testowego w jedną ramkę

```{r}
tree_df <- bind_cols(tree_pred, 'target' = df_test$spam)
head(tree_df)

reg_df <- bind_cols(reg_pred, 'target' = df_test$spam)
head(tree_df)
```

Dobrym podsumowaniem jakości modeli klasyfikacyjnych jest 'Confusion Matrix' czyli macierz pomyłek

```{r}
conf_tree <- conf_mat(tree_df, truth = "target", estimate = ".pred_class")
conf_tree
```

```{r}
autoplot(conf_tree, type = "heatmap")
```

```{r}
conf_reg <- conf_mat(reg_df, truth = "target", estimate = ".pred_class")
conf_reg
```

```{r}
autoplot(conf_reg, type = "heatmap")
```

Ewaluacja na wybranych metrykach możemy wyliczać przez odpowiednie funkcje

```{r}
accuracy(tree_df, truth = "target", estimate = ".pred_class")
sens(tree_df, truth = "target", estimate = ".pred_class")
j_index(tree_df, truth = "target", estimate = ".pred_class")
```

W celu narysowania krzywej ROC i polieczenia ROC AUC potrzebujemy mieć predykcję w postaci prawdopodobieństw. Możemy je uzyskać tak samo jak wcześniej dodając arugment `type`

```{r}
tree_pred <- predict(tree_wf_fit,df_test, type = "prob") #ramka danych z predykcją
head(tree_pred)

reg_pred <- predict(reg_wf_fit,df_test, type = "prob") #ramka danych z predykcją
head(reg_pred)
```

Łączymy predykcje modelu i wartość rzeczywistą ze zbioru testowego w jedną ramkę

```{r}
tree_df <- bind_cols(tree_pred, 'target' = df_test$spam)
head(tree_df)

reg_df <- bind_cols(reg_pred, 'target' = df_test$spam)
head(tree_df)
```

```{r}
roc_auc(tree_df, truth = "target", ".pred_0")
```

```{r}
roc_curve(tree_df, truth = "target", ".pred_0") %>% 
  autoplot()
```

lub możemy narosować korzystając z pakietu `ggplot2`

```{r}
tree_roc <- roc_curve(tree_df, truth = "target", ".pred_0")
ggplot()+
  geom_path(data=tree_roc,aes(x=1-specificity,y=sensitivity))
```

## Zapisywanie modelu

Jeżeli chcemy zapisać nasz wytrenowany model żeby użyć go np. w innym pliku możemy posłużyć się funkcją `saveRDS`

```{r}
saveRDS(tree_wf_fit, "tree_fit.rds")
```
