[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bootcamp 2023",
    "section": "",
    "text": "Preface\nTo jest projekt Bootcamp 2023 by KNUM ATLAS"
  },
  {
    "objectID": "1_intro.html",
    "href": "1_intro.html",
    "title": "Wstęp",
    "section": "",
    "text": "Spotkanie 1 - Wprowadzenie"
  },
  {
    "objectID": "1_intro.html#o-kole",
    "href": "1_intro.html#o-kole",
    "title": "Wstęp",
    "section": "1. O Kole",
    "text": "1. O Kole\n\n \n\n\n1. Podstawowe informacje dotyczące Koła\n\n\nKoło zostało założone w lipcu 2023 r.\n\n\nFunkcjonuje przy Katedrze Matematyki Stosowanej Wydziału Matematyki i Informatyki Technicznej\n\n\nOpiekunem Koła jest mgr inż. Magdalena Piłat-Rożek\n\n\nZarząd na ten rok akademicki:\n\n\n\nPaweł Woźniak - Prezes\n\n\nKacper Wójtowicz - Wiceprezes\n\n\nPatryk Marek - Sekretarz\n\n\nMichał Koziński - Skarbnik\n\n\n\n\n\n\n2. Cele Koła\nCelem Koła jest poszerzanie wiedzy studentów przede wszystkim na tematy związane z uczeniem maszynowym oraz sztuczną inteligencją. Chcemy tego dokonać poprzez:\n\n\nOrganizację corocznych bootcampów - takich jak ten!\n\n\nStudy Groups - podzielenie członków Koła na grupy, które skupiałyby się bardziej szczegółowo na jakichś tematach, np. Computer Vision, NLP itd.\n\n\nWyjazdy na Hackathony oraz konferencje związane z ML/AI\n\n\nUdział w projektach naukowych i dydaktycznych Katedry Matematyki Stosowanej\n\n\nOrganizację prelekcji\n\n\n\n\n3. Dotychczasowe aktywności\n\n\nHackathony\n\n\n\nKNUM x Golem Hackathon 2022\n\n\nBEST Hacking League 2023 (3. miejsce w kategorii Artificial Intelligence)\n\n\nHackYeah 2023\n\n\n\nNoc inżynierów 2023\n\n\nLubelski Festiwal Nauki 2023\n\n\nData Saturday 2023\n\n\nML in PL Conference 2023 (soon)\n\n\n\n\n4. Dołączenie do Koła\nZainteresowanych dołączeniem do Koła prosimy o wypełnienie formularza."
  },
  {
    "objectID": "1_intro.html#struktura-bootcampu",
    "href": "1_intro.html#struktura-bootcampu",
    "title": "Wstęp",
    "section": "2. Struktura bootcampu",
    "text": "2. Struktura bootcampu\n\n\nOdbędą się 4 spotkania\n\n\n\nWprowadzenie\n\n\nRegresja\n\n\nKlasyfikacja\n\n\nPodsumowanie & feedback\n\n\n\nKażde spotkanie ma przygotowaną część teoretyczną oraz praktyczną, zarówno w R jak i Pythonie.\n\n\nPo trzecim spotkaniu udostępnimy konkurs, w którym będziecie mogli sprawdzić swoje umiejętności"
  },
  {
    "objectID": "1_intro.html#dane",
    "href": "1_intro.html#dane",
    "title": "Wstęp",
    "section": "3. Dane",
    "text": "3. Dane\n\nPodstawowe pojęcia\n\n \n\nPoniższe dane pochodzą ze zbioru penguins z pakietu palmerpenguins w R.  Korzystając z poniższej tabeli odpowiemy sobie teraz na kilka podstawowych pytań:\n\n\nCzym jest obserwacja?\n\n\nCzym jest cecha?\n\n\nJakie wyróżniamy typy cech?\n\n\nCzym jest predyktor/zmienna niezależna?\n\n\nCzym jest target/zmienna niezależna?\n\n\n\n\n\n\n\n\n\n \n  \n    species \n    island \n    bill_length_mm \n    bill_depth_mm \n    flipper_length_mm \n    body_mass_g \n    sex \n    year \n  \n \n\n  \n    Adelie \n    Torgersen \n    39.1 \n    18.7 \n    181 \n    3750 \n    male \n    2007 \n  \n  \n    Adelie \n    Torgersen \n    39.5 \n    17.4 \n    186 \n    3800 \n    female \n    2007 \n  \n  \n    Adelie \n    Torgersen \n    40.3 \n    18.0 \n    195 \n    3250 \n    female \n    2007 \n  \n  \n    Adelie \n    Torgersen \n    NA \n    NA \n    NA \n    NA \n    NA \n    2007 \n  \n  \n    Adelie \n    Torgersen \n    36.7 \n    19.3 \n    193 \n    3450 \n    female \n    2007 \n  \n  \n    Adelie \n    Torgersen \n    39.3 \n    20.6 \n    190 \n    3650 \n    male \n    2007 \n  \n\n\n\n\n\n\n\n\nOdpowiedzi\n\n\n\nObserwacja to pojedynczy wiersz w tabeli.\n\n\nCecha to pojedyncza kolumna, służy do opisu danej obserwacji, w naszej tabeli jest to np. body_mass_g lub Species.\n\n\nCechy, zwane też zmiennymi, dzielimy na:\n\n\n\nZmienne typu ciągłego - przyjmują dowolne wartości liczbowe z \\(\\mathbb{R}\\), np. bill_depth_mm.\n\n\nZmienne typu jakościowego - są to nieporównywalne między sobą stany, gdzie jeden nie jest lepszy od drugiego, np. Species.\n\n\nZmienne typu porządkowego - są to zmienne typu jakościowego, lecz mają ustalony porządek, w naszym zbiorze nie znajduje się taka zmienna, ale mogłoby to być np. wykształcenie, gdzie podstawowe < średnie < wyższe.\n\n\n\nPredyktorem nazywamy cechę, która wykorzystywana będzie do przewidywania wartości zmiennej wynikowej (targetu/zmiennej niezależnej), w naszej tabelce jest to np. zmienna body_mass_g.\n\n\nInaczej zmienna wynikowa. Cecha, którą będziemy przewidywać, w rzeczywistości jest to wartość nieznana. W powyższym zbiorze może to być Species, czyli gatunek pingwina.\n\n\n\n\n\nPodział danych\n\n \n\n Dane dzielimy na zbiór treningowy i testowy. Zbiór treningowy zazwyczaj stanowi większość wszystkich obserwacji, często jest to 70-90%, zależnie od liczby obserwacji, którymi dysponujemy. Ten pierwszy wykorzystujemy do nauczenia modelu. Wszystkie operacje, np. normalizacja, wykonujemy tylko na zbiorze uczącym. Do zbioru testowego wracamy dopiero, gdy mamy gotowy model. Używamy go w celu określenia skuteczności naszego modelu. Dlaczego to ważne?\n\n\nPrzeuczenie i niedouczenie\n\n \n\n W rzeczywistości w zadaniach modelowania możemy mieć do czynienia z trzema sytuacjami.\n\n\nModel jest niedouczony - jest słabo dopasowany zarówno do danych treningowych, jak i testowych. Słabe wyniki predykcji w tym przypadku mogą wynikać z czynników takich jak:\n\n\n\nZbyt mały zbiór uczący\n\n\nZa mało predyktorów\n\n\nDostępne predyktory nie mówią wystarczająco dużo o zmiennej wynikowej.\n\n\nModel jest zbyt prosty, nie jest w stanie odwzorować skomplikowanych zależności pomiędzy cechami.\n\n\n\nModel jest dobrze nauczony - w takiej sytuacji model osiąga dobre, zbliżone wyniki na zbiorze treningowym i testowym.\n\n\nModel jest przeuczony - w tej sytuacji model osiąga zadowalające wyniki na zbiorze treningowym, natomiast ze zbiorem testowym radzi sobie dużo gorzej. Przeuczenie może wynikać z takich rzeczy jak:\n\n\n\nZbyt mały zbiór uczący\n\n\nModel jest zbyt złożony\n\n\n\n\n\n\n\n\n\nPrzykład pochodzi z www.towardsdatascience.com"
  },
  {
    "objectID": "1_intro.html#czym-jest-uczenie-maszynowe-czyli-jak-uczą-się-modele",
    "href": "1_intro.html#czym-jest-uczenie-maszynowe-czyli-jak-uczą-się-modele",
    "title": "Wstęp",
    "section": "4. Czym jest uczenie maszynowe, czyli jak uczą się modele?",
    "text": "4. Czym jest uczenie maszynowe, czyli jak uczą się modele?\n\n \n\n Tradycyjne programowanie algorytmów polega na tworzeniu zasad w celu otrzymania wyniku. W uczeniu maszynowym pokazujemy specjalnemu algorytmowi dane, wraz z wynikiem w celu znalezienia reguł, wzorców, pozwalających na otrzymywanie odpowiedzi dla nowych, nieznanych obserwacji.  W tradycyjnym programowaniu jeśli pojawiłaby się nowa obserwacja, nie wpasowująca się w tworzone reguły, nie będziemy w stanie otrzymać poprawnej odpowiedzi.\n\n \n\n Algorytmy uczenia maszynowego możemy podzielić na nadzorowane (ang. supervised) i nienadzorowane (ang. unsupervised). W uczeniu nadzorowanym mamy “nauczyciela”, który najczęściej jest zmienną wynikową i mówi algorytmowi jaka jest odpowiedź przy zadanych wartościach cech, co pozwala ustalić mu zależności. Na przykład, jeśli chcemy wykryć, czy dany mail jest spamem, czy nie i dysponujemy zbiorem, który zawiera wiadomości z oznaczeniem, czy były spamem, czy nie, wtedy skorzystamy z algorytmów uczenia nadzorowanego. \nW uczeniu nienadzorowanym nie mamy “nauczyciela”, dysponujemy obserwacjami bez zmiennej wynikowej. Z takich algorytmów korzystamy, np. w algorytmach grupujących, gdzie wcześniej nie znamy grup, do których należą obserwacje, czyli nie ma nauczyciela. Algorytmów grupujących używamy, żeby np. stwierdzić, że żywieniowo Polska jest bardziej podobna do Ukrainy, a Hiszpania jest bardziej podobna do Portugalii. \n\n \n\n\n\nRegresja i klasyfikacja\nAlgorytmy uczenia nadzorowanego możemy dalej podzielić na algorytmy regresyjne i klasyfikacyjne. Zadania regresyjne służą przewidywaniu ciągłych wartości, np. ceny mieszkania, miesięcznych wydatków klienta w naszym sklepie itd. Zadania klasyfikacyjne służą przewidywaniu wartości dyskretnych, np. czy klient kupi nasz produkt lub czy wiadomość jest spamem.\n\n\nFunkcja straty\n\n\nA way to measure whether the algorithm is doing a good job — This is necessary to determine the distance between the algorithm’s current output and its expected output. The measurement is used as a feedback signal to adjust the way the algorithm works. This adjustment step is what we call learning.\n\n\nFrançois Chollet,  Deep learning with Python (2017), Manning, chapter 1 p.6 \n\n\nFunkcja straty jest funkcją, która oblicza odległość pomiędzy obecną przewidywaną wartością, a oczekiwaną. Funkcja straty ewaluuje to, jak dobrze algorytm modeluje dane. Funkcje straty używane są zarówno dla zadań regresyjnych, jak i klasyfikacyjnych.\n\nMean Square Error Loss\nBłąd średniokwadratowy jest prostą i bardzo popularną funkcją straty. Używany jest do zadań regresyjnych. Jest to suma kwadratów różnic pomiędzy przewidywaną, a prawdziwą wartością. Wzór na MSE: \\[MSE = \\frac{1}{n}\\sum_{i=0}^{n}(y_i-\\hat{y}_i)^2, \\] gdzie:       – \\(n\\) - liczba obserwacji  – \\(y_i\\) - i-ta obserwacja  – \\(\\hat{y}_i\\) - predykcja dla i-tej obserwacji \nPoszukiwanie optymalnej (minimalnej) wartości funkcji straty można sobie wyobrazić jako “kule toczącą się po płaszczyźnie” poszukujęcej globalnego minimum (w naszym przykładzie “dołka który leży najniżej)"
  },
  {
    "objectID": "1_intro.html#z-czego-będziemy-korzystali",
    "href": "1_intro.html#z-czego-będziemy-korzystali",
    "title": "Wstęp",
    "section": "Z czego będziemy korzystali?",
    "text": "Z czego będziemy korzystali?\n\nR\n\nJęzyk R - dostępny do pobrania na CRAN (link).\nIDE - środowisko programistyczne, polecamy Rstudio (link).\nRtools - zestaw narzędzi do R (wersja dla Windows: link).\nBiblioteki - będziemy instalować na bieżąco, najwżaniejsze będą tidyverse i tidymodels.\n\n\n\nPython\n\nJęzyk Python - polecamy dystrybucję Anaconda (link)\nIDE - głównie Jupyter Notebook (instalowany razem z Anacondą), polecamy też Visual Studio Code i PyCharm.\nBiblioteki - będziemy instalować na bieżąco, najważniejsze będą: pandas, NumPy, Matplotlib i scikit-learn"
  },
  {
    "objectID": "2_regresja.html",
    "href": "2_regresja.html",
    "title": "Regresja",
    "section": "",
    "text": "Spotkanie 2 - Regresja"
  },
  {
    "objectID": "2_regresja.html#regresja-liniowa",
    "href": "2_regresja.html#regresja-liniowa",
    "title": "Regresja",
    "section": "Regresja liniowa",
    "text": "Regresja liniowa\n\nCzym jest regresja liniowa?\nPrzypomnienie z poprzedniego spotkania:\nW zadaniu regresyjnym na podstawie zbioru cech obserwacji - w naszym przypadku danych samochodów\n\n\n\n\n \n  \n      \n    mpg \n    cyl \n    disp \n    hp \n    drat \n    wt \n    qsec \n    vs \n    am \n    gear \n    carb \n  \n \n\n  \n    Mazda RX4 \n    21.0 \n    6 \n    160 \n    110 \n    3.90 \n    2.620 \n    16.46 \n    0 \n    1 \n    4 \n    4 \n  \n  \n    Mazda RX4 Wag \n    21.0 \n    6 \n    160 \n    110 \n    3.90 \n    2.875 \n    17.02 \n    0 \n    1 \n    4 \n    4 \n  \n  \n    Datsun 710 \n    22.8 \n    4 \n    108 \n    93 \n    3.85 \n    2.320 \n    18.61 \n    1 \n    1 \n    4 \n    1 \n  \n  \n    Hornet 4 Drive \n    21.4 \n    6 \n    258 \n    110 \n    3.08 \n    3.215 \n    19.44 \n    1 \n    0 \n    3 \n    1 \n  \n  \n    Hornet Sportabout \n    18.7 \n    8 \n    360 \n    175 \n    3.15 \n    3.440 \n    17.02 \n    0 \n    0 \n    3 \n    2 \n  \n  \n    Valiant \n    18.1 \n    6 \n    225 \n    105 \n    2.76 \n    3.460 \n    20.22 \n    1 \n    0 \n    3 \n    1 \n  \n\n\n\n\n\nChcemy przewidywać zmienną typu ciągłego - w naszym przypadku spalanie\n\n\n\n\n \n  \n      \n    mpg \n    cyl \n    disp \n    hp \n    drat \n    wt \n    qsec \n    vs \n    am \n    gear \n    carb \n  \n \n\n  \n    Mazda RX4 \n    21.0 \n    6 \n    160 \n    110 \n    3.90 \n    2.620 \n    16.46 \n    0 \n    1 \n    4 \n    4 \n  \n  \n    Mazda RX4 Wag \n    21.0 \n    6 \n    160 \n    110 \n    3.90 \n    2.875 \n    17.02 \n    0 \n    1 \n    4 \n    4 \n  \n  \n    Datsun 710 \n    22.8 \n    4 \n    108 \n    93 \n    3.85 \n    2.320 \n    18.61 \n    1 \n    1 \n    4 \n    1 \n  \n  \n    Hornet 4 Drive \n    21.4 \n    6 \n    258 \n    110 \n    3.08 \n    3.215 \n    19.44 \n    1 \n    0 \n    3 \n    1 \n  \n  \n    Hornet Sportabout \n    18.7 \n    8 \n    360 \n    175 \n    3.15 \n    3.440 \n    17.02 \n    0 \n    0 \n    3 \n    2 \n  \n  \n    Valiant \n    18.1 \n    6 \n    225 \n    105 \n    2.76 \n    3.460 \n    20.22 \n    1 \n    0 \n    3 \n    1 \n  \n\n\n\n\n\nZałóżmy że naszym celem jest ustalenie jak wygląda zależność pomiędzy liczbą koni mechanicznych a spalaniem\n\n\n\n\n\nW celu rozwiązania tego zadania i znalezienia prostej która najlepiej odda tę zależność możemy posłużyć się regresją liniową.\nW naszym wypadku wzór byłby następujący:\n\\[\\text{mpg} = \\beta_0 + \\beta_1 \\cdot \\text{hp}\\]\nGdzie:\n– \\(\\beta_0\\) jest wyrazem wolnym\n– \\(\\beta_1\\) jest współczynnikiem dla liczby koni mechanicznych\nCo można uogólnić na dowolną liczbę cech których użyjemy do budowy modelu (oznaczone jako \\(x_i\\))\n\\[y = \\beta_0 + \\beta_1x_1\\]\n\n\nJak wyznaczyć współczynniki?\nNa poprzednim spotkaniu mówiliśmy o funkcjach straty oraz optymalizacji ich wartości w celu znalezienia najlepszego modelu - te same zasady dotyczą regresji liniowej!\nNajpopularniejszą funkcją straty jest MSE, dla przypomnienia:\n\\[MSE = \\frac{1}{n}\\sum_{i=0}^{n}(y_i-\\hat{y}_i)^2, \\] gdzie:\n– \\(n\\) - liczba obserwacji  – \\(y_i\\) - i-ta obserwacja  – \\(\\hat{y}_i\\) - predykcja dla i-tej obserwacji\nDla regresji z jedną zmienną będzie to:\n\\[MSE = \\frac{1}{n}\\sum_{i=0}^{n}(y_i-\\beta_0 + \\beta_1x_1)^2, \\]\na dokładniej w naszym przypadku\n\\[MSE = \\frac{1}{n}\\sum_{i=0}^{n}(y_i-\\beta_0 + \\beta_1\\cdot\\text{hp})^2, \\]"
  },
  {
    "objectID": "2_regresja.html#regresja-w-działaniu",
    "href": "2_regresja.html#regresja-w-działaniu",
    "title": "Regresja",
    "section": "Regresja w działaniu",
    "text": "Regresja w działaniu\n\n\n\nLinie regresji poprowadzone dla naszych obserwacji wyglądają następująco\n\n\n\n\n\nZ tych trzech natomiast niebieska jest regresją dla której oba współczniki są dobrane poprzez optymalizacje funkcji starty\nDo określenia jakości naszego modelu możemy użyć metryki \\(R^2\\) określanej jako kwadrat wyjaśnianej wriancji. Mowiąc prościej, ile procent zmienności zmiennej wynikowej jest uchwycone za pomocą wykorzystanych predyktorów.\nMetryka ta przyjmuje wartości od \\(0\\) co oznacza że nie ma żadnej zależności do \\(1\\) co oznacza że zależność jest idelanie liniowa\nDla naszego modelu \\(R^2=0.59\\) czyli za pomocą danych jedynie o koniach mechanicznych auta jesteśmy w stanie wyjaśnić około \\(60\\%\\) zmienności spalania."
  },
  {
    "objectID": "2_regresja.html#regresja-wielomianowa",
    "href": "2_regresja.html#regresja-wielomianowa",
    "title": "Regresja",
    "section": "Regresja wielomianowa",
    "text": "Regresja wielomianowa\n\n\n\nMożna zauważyć, że na naszym przykładzie punkty układają się nie do końca w linii prostej dlatego można zastanowić się czy nie byłoby lepiej użyć do tego zadania jakiejś funkcji nieliniowej?\nW tym celu możemy posłużyć się regresją wielomianową, jak sama nazwa wskazuje w tym przypadku zamiast linii prostej będziemy modelować zależność przy wykorzystaniu wielomianu.\nSpróbujmy dodatkowo włączyć do modelu konie mechaniczne w drugiej potędze\nWzór na MSE będzie wyglądał podobnie jak dla modelu liniowego z tą różnicą, że dodajemy nasz predyktor w drugiej potędze z własnym współczynnikiem\n\\[MSE = \\frac{1}{n}\\sum_{i=0}^{n}(y_i-\\beta_0 + \\beta_1\\cdot\\text{hp} + \\beta_2 \\cdot \\text{hp}^2)^2, \\]\n\n\n\n\n\n\nUWAGA\n\n\n\nPrzy włączaniu predyktora w wyższej potędze, musi on być włączony również we wszystkich niższych potęgach.\nKażdy z predyktorów ma inny współczynnik \\(\\beta\\) pomimo faktu że są tą samą cechą w różnych potęgach\n\n\n\nNasza krzywa naniesiona na punkty wygląda następująco:\n\n\n\n\n\nModel ten charakteruzyje się \\(R^2=0.76\\) co czyni go lepszym od poprzedniego ponieważ wyjaśnia \\(16\\%\\) zmienności więcej.\nAle czy na pewno jest to aż tak dobry model?\n\n\nOdpowiedzi\n\nDo 200-250 koni mechanicznych zależność rzeczywiście jest lepiej odwzorowana niż w modelu liniowym, natomiast powyżej tej wartości spodziewamy się że spalanie powinno dalej rosnąć natomiast model powyżej 250 koni mechanicznych przewiduje, że spalanie będzie maleć.\nMoże do doprowadzić do sytuacji gdzie wprowadzona obserwacja spoza zakresu uczenia np. samochód z 500 koniami mechanicznymi z takiego modelu może uzyskać predykcje spalania podobną jak dla samochodu ze 100 koniami.\n\n\nJak możemy w takim razie poprawć ten model?\nUłożenie punktów może nam sugerować, że lepsza tutaj będzie zależność hiperboliczna\n\n\n\n\n\n\n\n\nModel ten charakteruzyje się \\(R^2=0.74\\) czyli tylko \\(2\\%\\) mniej od modelu opisanego wielomianem kwadratowym, natomiast w tym przypadku zależność ta będzie bliższa rzeczywistości."
  },
  {
    "objectID": "2_regresja.html#regresja-wieloraka",
    "href": "2_regresja.html#regresja-wieloraka",
    "title": "Regresja",
    "section": "Regresja wieloraka",
    "text": "Regresja wieloraka\nPrzy wykorzytaniu jednej cechy ciężko będzie zamodelować zależności wystepujące w prawdziwym świecie :).\nW celu uzyskania lepszego opisu zależności możemy wykorzystać regresję wieloraką, czyli regresję w której używamy wiele cech jednocześnie\nUogólniając wcześniej przedstawiony wzór na regresję liniową, regresję wieloraką zapisujemy następująco (gdzie \\(x_i\\) to cechy)\n\\[y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2+\\cdots+\\beta_nx_n\\]\nDla naszego zadania moglibyśmy zbudować następujący model\ndisp, hp, qsec, wt, drat\n\\[\\text{mpg} = \\beta_0 + \\beta_1 \\cdot \\text{hp} + \\beta_2 \\cdot \\text{disp} + \\beta_3 \\cdot \\text{qsec} + \\beta_4 \\cdot \\text{wt} + \\beta_5 \\cdot \\text{drat}\\]\n\n\n\nTen model cechuje się \\(R^2 = 0.85\\) czyli uzyskaliśmy w ten sposób \\(10\\%\\) więcej wyjaśnianej zmienności względem najlepszego modelu zbudowanego na tylko jednym predyktorze."
  },
  {
    "objectID": "2_regresja.html#uwagi-końcowe",
    "href": "2_regresja.html#uwagi-końcowe",
    "title": "Regresja",
    "section": "Uwagi końcowe",
    "text": "Uwagi końcowe\n\nRegresja wielomianowa i regresja wieloraka są również regresjami liniowymi.\nW rzeczywistości lepszą miarą od \\(R^2\\) jest jego skorygowana wersja oznaczana jako \\(R^2_{adj}\\) ponieważ zwykłe \\(R^2\\) będzie rosło pomimo dodawania do modelu nieistotnych predyktorów.\nW regresji można stosować regularyzację np. Ridge lub LASSO w celu uniknięcia nadmiernego dopasowania.\nRegresja liniowa ma wiele założeń które trzeba spełnić aby móc poprawnie wnioskować na jej podstawie. W zadaniu predykcyjnym (tak jak w naszym przypadku) nie musimy się nimi przejmować ponieważ chcemy tylko aby model jak najlepiej przewidywał zmienną wynikową."
  },
  {
    "objectID": "2_regresja.html#zadanie",
    "href": "2_regresja.html#zadanie",
    "title": "Regresja",
    "section": "Zadanie",
    "text": "Zadanie\nDo dyspozycji macie dane (link) dotyczące przewidywanej długości życia zebrane w 193 państwach na przestrzeni 15 lat.\nDane zawierają 18 kolumn z takimi informacjami jak:\n\nOdsetek zgonów w różnym wieku\nSzczepienia noworodków\nWskaźniki w kontekście państwa (np. GDP, wydatki na służbe zdrowia)\n\nZbudujcie model regresji liniowej przewidujący długość życia na podstawie dostępnych kolumn. Jakie wyszło RMSE? Czy błąd jest wysoki czy niski?\nDla zaawansowanych:\n\nUzupełnić braki danych.\nWykonać model w tidymodels.\nDodać regularyzację."
  }
]