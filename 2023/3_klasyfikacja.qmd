# Koło Naukowe Uczenia Maszynowego ATLAS - Bootcamp 2023 {.unnumbered}

---
author: "KNUM ATLAS"
format: 
  html:
    toc: true
    embed-resources: true
    self-contained: true
    page-layout: full
date: "02-06-2023"
---

# Spotkanie 3 - Klasyfikacja
___

### Czym jest klasyfikacja?

Klasyfikacja to zadanie w którym chcemy przypisać obserwacje do danej klasy na podstawie prawdopodobieństwa przynależności. Obserwacje przypisujemy do klasy z największym prwadopodobieństwem.

Wyróżniamy kilka typów klasyfikacji:

<center>![](obrazki/example5.png){height=400}</center>

Najczęściej w klasycznych zadaniach uczenia maszynowego mamy do czynienia z klasyfikacją binarną i wieloklasową, natomiast wieloetykietowa jest częściej spotykana w zagadnieniach wizji komputerowej.

### Regresja logistyczna

Regresja logistyczna do modyfikacja regresji liniowej która zwraca zawsze prawdopodobieństwo z przedziału $[0,1]$ poprzez zastosowanie funkcji sigmoidalnej.

Przypomnijmy wzór na regresję liniową z jednym predyktorem:

$$y = \beta_0 + \beta_1x$$

Ta sama funkcja wykorzystywana jest w regresji logistycznej w następujący sposób:

$$p = \frac{e^{(\beta_0 + \beta_1x)}}{1+e^{(\beta_0 + \beta_1x)}} = \frac{1}{1+e^{-(\beta_0 + \beta_1x)}}$$

w tym przypadku na wyjściu zamiast wartości zmiennej wynikowej mamy prawdopodobieństwo przynależności do klas.

Regresja logistyczna w przypadku jednego predyktora wygląda następująco:

::: {layout-ncol=1}
![Grafika pochodzi z artykułu "Mitigation of nonlinear phase noise in single-channel coherent 16-QAM systems employing logistic regression"](obrazki/example6.png)
:::

### Drzewo decyzyjne

Kolejnym algorytmem uczenia maszynowego jest drzewo decyzyjne, które może być stosowane zarówno do zadań klasyfikacyjnych jak i regresyjnych.

Każde drzewo decyzyjne składa się z korzenia (ang. root), węzłów (ang. nodes) i liści (ang. leaves). Korzeniem nazywamy początkowy węzeł drzewa, z którego poprzez podziały (ang. splits) powstają kolejne węzły potomne. Końcowe węzły, które nie podlegają podziałom nazywamy liśćmi, a linie łączące węzły nazywamy gałęziami (ang. branches).

::: {layout-ncol=1}
![Grafika pochodzi z www.regenerativetoday.com](obrazki/example7.png)
:::

### Las losowy

Ze względu na ograniczone możliwości predykcyjne pojedynczego drzewa w przypadku bardziej złożonych zadań przegrywały jakością z innymi modelami.

W celu rozwiązania tego problemu postanowiono połączyć wiele pojedynczych drzew (słaby model) w jeden zagregowany model (silny model) - agregacje drzew decyzyjnych w jeden model nazywamy lasem losowym.

::: {.callout-note}
## Ważne

W przypadku budowy pojedynczego drzewa do budowy zazwyczaj wykorzystujemy wszystkie dostępne predyktory, natomiast drzewa wchodzące w skład lasu budowane są z losowanego dla każdego drzewa podzbioru predyktorów.
:::

::: {layout-ncol=1}
![Grafika pochodzi z www.turing.com](obrazki/example8.png)
:::

### Metryki

1.    Confusion Matrix - nie jest to stricte metryka ale jest wizualizacją skuteczności przeprowadzonej klasyfikacji pomocnej w ocenie modelu

::: {layout-ncol=1}
![Grafika pochodzi z www.plat.ai](obrazki/example9.png)
:::

2.    Accuracy - stosunek poprawnie zaklasyfikowanych obserwacji do wszystkich obserwacji. Czyli na przykładzie wyżej przedstawionej macierzy klasyfikacji byłoby to:

$$\text{Accuracy} = \frac{\text{TP}+\text{TN}}{\text{TP}+\text{TN}+\text{FP}+\text{FN}}$$

3.    Specificity (True negative rate)

$$\text{TNR} = \frac{\text{TN}}{\text{FP}+\text{TN}}$$

4.    Sensitivity (True positive rate)

$$\text{TPR} = \frac{\text{TP}}{\text{TP}+\text{FN}}$$

5.    False Positive Rate

$$FPR=\frac{FP}{FP+TN}=1-\text{specificity}$$

6.    AUC-ROC - ROC to skrót od Receiver Operator Characteristic, AUC to Area Under Curve.
Wykres ROC pokazuje nam jak klasyfikator radzi sobie przy różnych thresholdach. Im większe pole powierzchni pod krzywą tym lepiej.

::: {layout-ncol=1}
![Grafika pochodzi z www.plat.ai](obrazki/example10.png){width=500}
:::

#### Problem niezbalansowania klas
Gdy mierzymy się z problemem klasyfikacji, często klasy wynikowe będą niezbalansowane. Na przykład tak jak w sytuacji, gdzie sprawdzamy awaryjność maszyn. Naturalnym jest, że maszyny częściej nie będą się psuły, niż będą ulegały awarii.

::: {layout-ncol=1}
![](obrazki/example11.png){width=500, fig-align="center"}
:::

W takich sytuacjach niektóre metryki, np. accuracy nie będą dobre do oceny jakości dopasowania modelu. Dlaczego? Ponieważ jeśli 9900 obserwacji pochodzi z klasy 0, a 100 obserwacji pochodzi z klasy 1, to model wskazujący ZAWSZE klasę 0 będzie miał accuracy na poziomie 99%. Dlatego przy wynikach metryk ważny jest kontekst.

::: {.callout-note}
## Informacja

W przypadku niezbalansowania klas wynikowych zalecamy korzystanie z metryk takich jak AUC-ROC, J-index czy F1, aniżeli accuracy.
:::

Przy niezbalansowaniu klas, czy po prostu małej reprezentacji jednej z nich, modele mogą mieć problemy z odpowiednim znalezieniem wzorców i nauczeniem się przewidywania tej klasy.

Czy da się coś z tym zrobić? Tak, istnieją metody undersamplingu i oversamplingu, takie jak SMOTE czy ROSE, które pozwalają nam na radzenie sobie z tym problemem.

## Zadanie

Do dyspozycji macie dane ([link](https://drive.google.com/drive/u/3/folders/1DjpxNS2jocC_K4KK_slbXa-MLiPLp5oD)) (plik Healthcare-Diabetes.csv) dotyczące badań na cukrzycę zabrane przez Narodowy Instytut Cukrzycy oraz Chorób Układu Pokarmowego i Nerek w Stanach Zjednoczonych. Celem zadania jest zbudowanie modelu predykcyjnego do określenia na podstawie wyniku badań czy dany pacjent ma cukrzycę. W zbiorze znajdują się następujące kolumny:

-   Pregnancies - liczba ciąż

-   Glucose - poziom glukozy we krwi

-   BloodPressure - ciśnienie (mm Hg)

-   SkinThickness - grubość skóry na tricepsie (mm)

-   Insulin - insulina w surowicy (mu U/ml)

-   BMI - body mass index

-   DiabetesPedigreeFunction - funkcja rodowodu cukrzycy

-   Age - wiek

-   Outcome - zmienna wynikowa określająca czy pacjent ma cukrzycę